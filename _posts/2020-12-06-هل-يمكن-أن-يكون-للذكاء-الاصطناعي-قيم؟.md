---
date: 2020-12-06 11:27:22
layout: post
title: هل يمكن أن يكون للذكاء الاصطناعي قيم؟
subtitle: هل يمكننا إيقاف الذكاء الاصطناعي المارق بتعليمه أخلاقياته؟ .
description: ' تساءل الكثير من العلماء والفلاسفة وكتاب الخيال العلمي عن كيفية
  منع الذكاء الاصطناعي البشري الخارق المحتمل من تدميرنا جميعًا. في حين أن
  الإجابة واضحة من "فصله إذا كان يحاول قتلك" لديها العديد من المؤيدين (وأنه يعمل
  على و HAL 9000 )، '
image: /assets/img/uploads/unnamed.jpg
optimized_image: /assets/img/uploads/unnamed.jpg
category: التكنولوجيا
tags:
  - الذكاء الاصطناعي
author: Cocktail
paginate: true
---
تساءل الكثير من العلماء و الفلاسفة و كتاب الخيال العلمي عن كيفية منع الذكاء الاصطناعي البشري الخارق المحتمل من تدميرنا جميعًا. في حين أن الإجابة واضحة "افصله عن الكهرباء إذا كان يحاول قتلك" لديها العديد من المؤيدين ، فإنه ليس من الصعب جدا أن نتصور أن آلة متطورة بما فيه الكفاية سوف تكون قادرة على أن تمنعك من القيام بذلك . بدلاً من ذلك ، قد يكون الذكاء الاصطناعي القوي جدًا قادرًا على اتخاذ قرارات بسرعة كبيرة بحيث لا يستطيع البشر مراجعتها للتأكد من صحتها الأخلاقية أو تصحيح الضرر الذي تسببه.

يُطلق على مسألة الحفاظ على الذكاء الاصطناعي الذي يحتمل أن يكون إنسانًا خارقًا من الأشرار و إيذاء الناس "مشكلة التحكم" ، و هناك العديد من الحلول المحتملة لها. واحدة من أكثر المواضيع التي نوقشت بشكل متكرر هي " التوافق " و تتضمن مزامنة الذكاء الاصطناعي مع القيم و الأهداف و المعايير الأخلاقية الإنسانية. الفكرة هي أن الذكاء الاصطناعي المصمم بنظام أخلاقي مناسب لن يعمل بطريقة ضارة للبشر في المقام الأول.\
\
لكن مع هذا الحل تكمن الإشكالية في التفاصيل. أي نوع من الأخلاق يجب أن نعلمه الجهاز، أي نوع من الأخلاق *يمكن أن* نجعل متابعة الجهاز، و الذي يحصل للإجابة على هذه الأسئلة ؟

تناول إيسون غابرييل هذه الأسئلة في مقالته الجديدة " الذكاء الاصطناعي و القيم و المواءمة " . و يتناول هذه المشكلات بينما يشير إلى أن الإجابة عليها بشكل نهائي أكثر تعقيدًا مما تبدو عليه.

###  ما هو تأثير الطريقة التي نبني بها الآلة على الأخلاقيات التي يمكن للآلة اتباعها ؟

يجيد البشر حقًا شرح المشكلات الأخلاقية و مناقشة الحلول المحتملة. بعضنا جيد جدًا في تدريس أنظمة كاملة للأخلاق لأشخاص آخرين. و مع ذلك ، فإننا نميل إلى القيام بذلك باستخدام اللغة بدلاً من التعليمات البرمجية. نحن نعلم أيضًا الأشخاص الذين لديهم قدرات تعلم مشابهة لنا بدلاً من آلة ذات قدرات مختلفة. قد يؤدي التحول من الناس إلى الآلات إلى إدخال بعض القيود.\
\
يمكن تطبيق العديد من طرق التعلم الآلي المختلفة على النظرية الأخلاقية. المشكلة هي أنهم قد يثبتون أنهم قادرون جدًا على استيعاب موقف أخلاقي معين و غير قادرين تمامًا على التعامل مع موقف آخر.

التعلم المعزز (RL) هو طريقة لتعليم الآلة أن تفعل شيئًا من خلال جعلها تعظم إشارة المكافأة. من خلال التجربة و الخطأ ، تكون الآلة قادرة في النهاية على تعلم كيفية الحصول على أكبر قدر ممكن من المكافآت بكفاءة. مع ميله الداخلي إلى تعظيم ما يتم تعريفه على أنه جيد ، من الواضح أن هذا النظام يفسح المجال للنفعية ، بهدف تعظيم السعادة الكاملة ، و غيرها من النظم الأخلاقية العواقبية. لا تزال كيفية استخدامه لتدريس نظام أخلاقي مختلف بشكل فعال غير معروفة.\
\
بدلاً من ذلك ، يسمح التعلم المهني أو التعلم بالمحاكاة للمبرمج بإعطاء الكمبيوتر قائمة طويلة من البيانات أو نموذجًا لملاحظة و السماح للآلة باستنتاج القيم و التفضيلات منه. غالبًا ما يجادل المفكرون المهتمون بمشكلة المحاذاة بأن هذا يمكن أن يعلم الآلة تفضيلاتنا و قيمنا من خلال الأفعال بدلاً من اللغة المثالية. سيتطلب منا فقط أن نظهر للآلة نموذجًا أخلاقيًا و نطلب منها نسخ ما تفعله. الفكرة لديها أكثر من عدد قليل من أوجه التشابه مع الأخلاق الفضيلة .

\
في الوقت نفسه ، هناك بعض النظريات الأخلاقية التي لا نعرف كيف نعلمها للآلات. تعتمد النظريات الأخلاقية ، المعروفة بإنشاء قواعد عالمية للالتزام بها طوال الوقت ، عادةً على عامل أخلاقي لتطبيق المنطق على الموقف الذي يجدون أنفسهم فيه بجانب عوامل أخرى. لا توجد آلة حاليًا قادرة على فعل ذلك. حتى الفكرة الأكثر محدودية للحقوق ، و مفهوم أنه لا ينبغي انتهاكها بغض النظر عن أي شيء، قد يكون برمجته في الجهاز ، نظرًا لمدى التحديد و الوضوح الذي يتعين عليك القيام به لإنشاء هذه الحقوق.

بعد مناقشة هذه المشكلات ، يلاحظ جبرائيل أنه :\
\
"في ضوء هذه الاعتبارات ، يبدو من الممكن أن الأساليب التي نستخدمها لبناء عوامل مصطنعة قد تؤثر على نوع القيم أو المبادئ التي يمكننا ترميزها".\
\
هذه مشكلة حقيقية جدا. بعد كل شيء ، إذا كان لديك ذكاء اصطناعي فائق ، ألا ترغب في تعليمه أخلاقيات باستخدام تقنية التعلم الأنسب لكيفية بنائه ؟ ماذا تفعل إذا لم تستطع هذه التقنية أن تعلمه أي شيء غير مبدأ النفعية و لكنك قررت أن أخلاقيات الفضيلة هي الطريقة الصحيحةو الأنسب ؟

إذا لم يتمكن الفلاسفة من الاتفاق على الكيفية التي يجب أن يتصرف بها الناس ، فكيف سنكتشف كيف يجب أن يعمل الكمبيوتر فائق الذكاء؟

قد لا يكون الشيء المهم هو برمجة آلة بنظرية أخلاقية واحدة حقيقية ، بل التأكد من أنها تتماشى مع القيم و السلوكيات التي يمكن للجميع الموافقة عليها. يطرح غابرييل عدة أفكار حول كيفية تحديد القيم التي يجب أن يتبعها الذكاء الاصطناعي.

و هو يجادل بأنه يمكن العثور على مجموعة من القيم من خلال الإجماع. هناك قدر لا بأس به من التداخل في نظرية حقوق الإنسان بين ملتقى للفلسفة الأفريقية و الغربية و الإسلامية و الصينية. يمكن وضع مخطط للقيم ، بمفاهيم مثل "كل البشر لهم الحق في عدم التعرض للأذى ، بغض النظر عن مقدار المكاسب الاقتصادية التي قد تنتج عن إلحاق الأذى بهم" ، و التي يمكن وضعها و تأييدها من قبل أعداد كبيرة من الناس من جميع الثقافات.

بدلاً من ذلك ، قد يستخدم الفلاسفة "حجاب الجهل" ، و هي تجربة فكرية حيث يُطلب من الناس إيجاد مبادئ العدالة التي قد يدعمونها إذا لم يعرفوا ما هي مصالحهم الذاتية و حالتهم الاجتماعية في عالم يتبع تلك المبادئ ، لإيجاد قيم يتبعها الذكاء الاصطناعي. من المفترض أن تكون القيم التي يختارونها هي تلك التي من شأنها حماية الجميع من أي ضرر يمكن أن يسببه الذكاء الاصطناعي و ستضمن وصول فوائده إلى الجميع.\
\
أخيرًا ، يمكننا التصويت على القيم. بدلاً من معرفة ما قد يؤيده الناس في ظل ظروف معينة أو بناءً على الفلسفات التي يؤيدونها بالفعل ، يمكن للناس فقط التصويت على مجموعة من القيم التي يريدون أن يلتزم بها الذكاء الاصطناعي الفائق.\
\
كل هذه الأفكار مثقلة أيضًا بالنقص الحالي في الذكاء الاصطناعي الفائق. لا يوجد رأي إجماعي حول أخلاقيات الذكاء الاصطناعي حتى الآن ، و لم يكن الجدل الحالي عالميًا كما ينبغي أن يكون. سيحتاج المفكرون الذين يقفون وراء حجاب الجهل إلى معرفة ميزات الذكاء الاصطناعي التي يخططون لها عند الخروج بمخطط للقيم ، حيث من غير المرجح أن يختاروا مجموعة قيم لم يتم تصميم الذكاء الاصطناعي لمعالجتها بفعالية. يواجه النظام الديمقراطي صعوبات هائلة في ضمان إجراء "انتخابات" عادلة و شرعية للقيم التي يمكن أن يتفق عليها الجميع بشكل صحيح.

على الرغم من هذه القيود ، سنحتاج إلى إجابة لهذا السؤال عاجلاً و ليس آجلاً ؛ إن التوصل إلى القيم التي يجب أن نربطها بالذكاء الاصطناعي هو شيء تريد القيام به *قبل* أن يكون لديك كمبيوتر عملاق يمكن أن يسبب ضررًا هائلاً إذا لم يكن لديه بعض الاختلاف في البوصلة الأخلاقية لتوجيهه.\
\
في حين أن الذكاء الاصطناعي القوي بما يكفي للعمل خارج سيطرة الإنسان لا يزال بعيد المنال ، فإن مشكلة كيفية إبقائهم تحت السيطرة عند وصولهم لا تزال مهمة. إن مواءمة مثل هذه الآلات مع القيم و المصالح الإنسانية من خلال الأخلاق هي إحدى الطرق الممكنة للقيام بذلك ، لكن مشكلة ما يجب أن تكون عليه هذه القيم ، و كيفية تعليمها للآلة ، و من الذي يقرر الإجابات على هذه المشاكل لا تزال دون حل.
---
date: 2020-12-06 11:27:22
layout: post
title: هل يمكن أن يكون للذكاء الاصطناعي قيم؟
subtitle: هل يمكننا إيقاف الذكاء الاصطناعي المارق بتعليمه أخلاقياته؟ .
description: ' تساءل الكثير من العلماء والفلاسفة وكتاب الخيال العلمي عن كيفية
  منع الذكاء الاصطناعي البشري الخارق المحتمل من تدميرنا جميعًا. في حين أن
  الإجابة واضحة من "فصله إذا كان يحاول قتلك" لديها العديد من المؤيدين (وأنه يعمل
  على و HAL 9000 )، '
image: /assets/img/uploads/unnamed.jpg
optimized_image: /assets/img/uploads/unnamed.jpg
category: التكنولوجيا
tags:
  - الذكاء الاصطناعي
author: Cocktail
paginate: true
---
تساءل الكثير من العلماء والفلاسفة وكتاب الخيال العلمي عن كيفية منع الذكاء الاصطناعي البشري الخارق المحتمل من تدميرنا جميعًا. في حين أن الإجابة واضحة من "فصله إذا كان يحاول قتلك" لديها العديد من المؤيدين (وأنه يعمل على و HAL 9000 )، فإنه ليس من الصعب جدا أن نتصور أن آلة متطورة بما فيه الكفاية سوف تكون قادرة على تمنعك من القيام بذلك . بدلاً من ذلك ، قد يكون الذكاء الاصطناعي القوي جدًا قادرًا على اتخاذ قرارات بسرعة كبيرة بحيث لا يستطيع البشر مراجعتها للتأكد من صحتها الأخلاقية أو تصحيح الضرر الذي تسببه.

يُطلق على مسألة الحفاظ على الذكاء الاصطناعي الذي يحتمل أن يكون إنسانًا خارقًا من المارقة وإيذاء الناس "مشكلة التحكم" ، وهناك العديد من الحلول المحتملة لها. واحدة من أكثر المواضيع التي نوقشت بشكل متكرر هي " التوافق " وتتضمن مزامنة الذكاء الاصطناعي مع القيم والأهداف والمعايير الأخلاقية الإنسانية. الفكرة هي أن الذكاء الاصطناعي المصمم بنظام أخلاقي مناسب لن يعمل بطريقة ضارة بالبشر في المقام الأول.\
\
لكن مع هذا الحل يكمن الشيطان في التفاصيل. أي نوع من الأخلاق يجب أن نعلمه الجهاز، أي نوع من الأخلاق *يمكن أن* نجعل متابعة الجهاز، والذي يحصل للإجابة على هذه الأسئلة؟

تناول إيسون غابرييل هذه الأسئلة في مقالته الجديدة " الذكاء الاصطناعي والقيم والمواءمة " . ويتناول هذه المشكلات بينما يشير إلى أن الإجابة عليها بشكل نهائي أكثر تعقيدًا مما تبدو عليه.

###  ما هو تأثير الطريقة التي نبني بها الآلة على الأخلاقيات التي يمكن للآلة اتباعها؟

يجيد البشر حقًا شرح المشكلات الأخلاقية ومناقشة الحلول المحتملة. بعضنا جيد جدًا في تدريس أنظمة كاملة للأخلاق لأشخاص آخرين. ومع ذلك ، فإننا نميل إلى القيام بذلك باستخدام اللغة بدلاً من التعليمات البرمجية. نحن نعلم أيضًا الأشخاص الذين لديهم قدرات تعلم مشابهة لنا بدلاً من آلة ذات قدرات مختلفة. قد يؤدي التحول من الناس إلى الآلات إلى إدخال بعض القيود.\
\
يمكن تطبيق العديد من طرق التعلم الآلي المختلفة على النظرية الأخلاقية. المشكلة هي أنهم قد يثبتون أنهم قادرون جدًا على استيعاب موقف أخلاقي معين وغير قادرين تمامًا على التعامل مع موقف آخر.

التعلم المعزز (RL) هو طريقة لتعليم الآلة أن تفعل شيئًا من خلال جعلها تعظم إشارة المكافأة. من خلال التجربة والخطأ ، تكون الآلة قادرة في النهاية على تعلم كيفية الحصول على أكبر قدر ممكن من المكافآت بكفاءة. مع ميله الداخلي إلى تعظيم ما يتم تعريفه على أنه جيد ، من الواضح أن هذا النظام يفسح المجال للنفعية ، بهدف تعظيم السعادة الكاملة ، وغيرها من النظم الأخلاقية العواقبية. لا تزال كيفية استخدامه لتدريس نظام أخلاقي مختلف بشكل فعال غير معروفة.\
\
بدلاً من ذلك ، يسمح التعلم المهني أو التعلم بالمحاكاة للمبرمج بإعطاء الكمبيوتر قائمة طويلة من البيانات أو نموذجًا لملاحظة والسماح للآلة باستنتاج القيم والتفضيلات منه. غالبًا ما يجادل المفكرون المهتمون بمشكلة المحاذاة بأن هذا يمكن أن يعلم الآلة تفضيلاتنا وقيمنا من خلال العمل بدلاً من اللغة المثالية. سيتطلب منا فقط أن نظهر للآلة نموذجًا أخلاقيًا ونطلب منها نسخ ما تفعله. الفكرة لديها أكثر من عدد قليل من أوجه التشابه مع الأخلاق الفضيلة .

تظل مشكلة من هو نموذج أخلاقي للآخرين دون حل ، ومن ، إذا كان هناك أي شخص ، يجب أن يكون لدينا أجهزة كمبيوتر لمحاكاة هو أمر مطروح للنقاش.\
\
في الوقت نفسه ، هناك بعض النظريات الأخلاقية التي لا نعرف كيف نعلمها للآلات. تعتمد النظريات الأخلاقية ، المعروفة بإنشاء قواعد عالمية للالتزام بها طوال الوقت ، عادةً على عامل أخلاقي لتطبيق العقل على الموقف الذي يجدون أنفسهم فيه على طول خطوط معينة. لا توجد آلة حاليًا قادرة على فعل ذلك. حتى الفكرة الأكثر محدودية للحقوق ، ومفهوم أنه لا ينبغي انتهاكها بغض النظر عما يقوله أي اتجاه للتحسين ، قد يكون صعبًا على الكود في الجهاز ، نظرًا لمدى التحديد والوضوح الذي يتعين عليك القيام به لإنشاء هذه الحقوق.

بعد مناقشة هذه المشكلات ، يلاحظ جبرائيل أنه:\
\
"في ضوء هذه الاعتبارات ، يبدو من الممكن أن الأساليب التي نستخدمها لبناء عوامل مصطنعة قد تؤثر على نوع القيم أو المبادئ التي يمكننا ترميزها".\
\
هذه مشكلة حقيقية جدا. بعد كل شيء ، إذا كان لديك ذكاء اصطناعي فائق ، ألا ترغب في تعليمه أخلاقيات باستخدام تقنية التعلم الأنسب لكيفية بنائه؟ ماذا تفعل إذا لم تستطع هذه التقنية أن تعلمها أي شيء غير النفعية جيدًا ولكنك قررت أن أخلاقيات الفضيلة هي الطريقة الصحيحة للذهاب؟

إذا لم يتمكن الفلاسفة من الاتفاق على الكيفية التي يجب أن يتصرف بها الناس ، فكيف سنكتشف كيف يجب أن يعمل الكمبيوتر فائق الذكاء؟

قد لا يكون الشيء المهم هو برمجة آلة بنظرية أخلاقية واحدة حقيقية ، بل التأكد من أنها تتماشى مع القيم والسلوكيات التي يمكن للجميع الموافقة عليها. يطرح غابرييل عدة أفكار حول كيفية تحديد القيم التي يجب أن يتبعها الذكاء الاصطناعي.

وهو يجادل بأنه يمكن العثور على مجموعة من القيم من خلال الإجماع. هناك قدر لا بأس به من التداخل في نظرية حقوق الإنسان بين مقطع عرضي للفلسفة الأفريقية والغربية والإسلامية والصينية. يمكن وضع مخطط للقيم ، بمفاهيم مثل "كل البشر لهم الحق في عدم التعرض للأذى ، بغض النظر عن مقدار المكاسب الاقتصادية التي قد تنتج عن إلحاق الأذى بهم" ، والتي يمكن وضعها وتأييدها من قبل أعداد كبيرة من الناس من جميع الثقافات.

بدلاً من ذلك ، قد يستخدم الفلاسفة "حجاب الجهل" ، وهي تجربة فكرية حيث يُطلب من الناس إيجاد مبادئ العدالة التي قد يدعمونها إذا لم يعرفوا ما هي مصالحهم الذاتية وحالتهم الاجتماعية في عالم يتبع تلك المبادئ ، لإيجاد قيم يتبعها الذكاء الاصطناعي. من المفترض أن تكون القيم التي يختارونها هي تلك التي من شأنها حماية الجميع من أي ضرر يمكن أن يسببه الذكاء الاصطناعي وستضمن وصول فوائده إلى الجميع.\
\
أخيرًا ، يمكننا التصويت على القيم. بدلاً من معرفة ما قد يؤيده الناس في ظل ظروف معينة أو بناءً على الفلسفات التي يؤيدونها بالفعل ، يمكن للناس فقط التصويت على مجموعة من القيم التي يريدون أن يلتزم بها الذكاء الاصطناعي الفائق.\
\
كل هذه الأفكار مثقلة أيضًا بالنقص الحالي في الذكاء الاصطناعي الفائق. لا يوجد رأي إجماعي حول أخلاقيات الذكاء الاصطناعي حتى الآن ، ولم يكن الجدل الحالي عالميًا كما ينبغي أن يكون. سيحتاج المفكرون الذين يقفون وراء حجاب الجهل إلى معرفة ميزات الذكاء الاصطناعي التي يخططون لها عند الخروج بمخطط للقيم ، حيث من غير المرجح أن يختاروا مجموعة قيم لم يتم تصميم الذكاء الاصطناعي لمعالجتها بفعالية. يواجه النظام الديمقراطي صعوبات هائلة في ضمان إجراء "انتخابات" عادلة وشرعية للقيم التي يمكن أن يتفق عليها الجميع بشكل صحيح.

على الرغم من هذه القيود ، سنحتاج إلى إجابة لهذا السؤال عاجلاً وليس آجلاً ؛ إن التوصل إلى القيم التي يجب أن نربطها بالذكاء الاصطناعي هو شيء تريد القيام به *قبل* أن يكون لديك كمبيوتر عملاق يمكن أن يسبب ضررًا هائلاً إذا لم يكن لديه بعض الاختلاف في البوصلة الأخلاقية لتوجيهه.\
\
في حين أن الذكاء الاصطناعي القوي بما يكفي للعمل خارج سيطرة الإنسان لا يزال بعيد المنال ، فإن مشكلة كيفية إبقائهم في الطابور عند وصولهم لا تزال مهمة. إن مواءمة مثل هذه الآلات مع القيم والمصالح الإنسانية من خلال الأخلاق هي إحدى الطرق الممكنة للقيام بذلك ، لكن مشكلة ما يجب أن تكون عليه هذه القيم ، وكيفية تعليمها للآلة ، ومن الذي يقرر الإجابات على هذه المشاكل لا تزال دون حل.